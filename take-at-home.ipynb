{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS1.A (5 points) - Data Exploration\n",
    "\n",
    "Create a pandas frame of the dataset and _print_ the first 5 rows in format where the first row will show the column names of the dataset. Instead of the feature names you can conveniently use the column index as a name.  \n",
    "\n",
    "Is the 2nd column which is the query id a feature or not ?  Answer the question by coding the production of the $\\mathbf x$ feature container and the $label y$ label container.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_txt('C:\\Users\\snoop\\OneDrive\\Documents\\CS 482\\Querylevelnorm.txt')\n",
    "print(dataset.head(5))\n",
    "x = dataset.drop(columns=['column_index'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS1.B (20 points)\n",
    "\n",
    "Consult your textbook notebook `#4`` (the one that corresponds to Chapter 4) and express the problem of ranking as a regression problem. State the problem and implement the solution using the polynomial basis functions just like in [this notebook](https://pantelis.github.io/data-mining/aiml-common/lectures/regression/linear-regression/linear_regression.html). Solve the linear regression problem using SGD. Report the train and test MSE as a function of the epochs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from prml.preprocess import GaussianFeature, PolynomialFeature, SigmoidalFeature\n",
    "from prml.linear import (\n",
    "    BayesianRegression,\n",
    "    EmpiricalBayesRegression,\n",
    "    LinearRegression,\n",
    "    RidgeRegression\n",
    ")\n",
    "\n",
    "np.random.seed(1234)\n",
    "def create_toy_data(func, sample_size, std, domain=[0, 1]):\n",
    "    x = np.linspace(domain[0], domain[1], sample_size)\n",
    "    np.random.shuffle(x)\n",
    "    y = func(x) + np.random.normal(scale=std, size=x.shape)\n",
    "    return x, y\n",
    "\n",
    "def sinusoidal(x):\n",
    "    return np.sin(2 * np.pi * x)\n",
    "\n",
    "x_train, y_train = create_toy_data(sinusoidal, 10, 0.25)\n",
    "x_test = np.linspace(0, 1, 100)\n",
    "y_test = sinusoidal(x_test)\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "plt.plot(x_test, y_test, label=\"$\\sin(2\\pi x)$\")\n",
    "plt.plot(x_test, y_test, \"-g\", label=\"Target Function\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "x = np.linspace(-1, 1, 100)\n",
    "X_polynomial = PolynomialFeature(11).transform(x[:, None])\n",
    "X_gaussian = GaussianFeature(np.linspace(-1, 1, 11), 0.1).transform(x)\n",
    "X_sigmoidal = SigmoidalFeature(np.linspace(-1, 1, 11), 10).transform(x)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i, X in enumerate([X_polynomial, X_gaussian, X_sigmoidal]):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    for j in range(12):\n",
    "        plt.plot(x, X[:, j])\n",
    "txt=\"Polynomial, Gaussian and Sigmoidal basis functions\"\n",
    "plt.figtext(0.5, 0.01, txt, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "y = np.dot(X, np.array([1, 2, 3, 4, 5]))\\\n",
    "    + np.random.randn(100) * 0.1\n",
    "# Create an instance of the SGD class\n",
    "model = SGD(lr=0.01, max_iter=1000,\n",
    "            batch_size=32, tol=1e-3)\n",
    "model.fit(X, y)\n",
    "# Predict using predict method from model\n",
    "y_pred = model.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PS1.C (15 points)\n",
    "\n",
    "Repeat the exercise of PS 1.B with the additional regualrization approach of  [this notebook](https://pantelis.github.io/data-mining/aiml-common/lectures/regression/linear-regression/linear_regression.html). Optimize $\\lambda$ showing the train and test MSE as a function of this hyperparameter and for the optimal value of $\\lambda$ plot the final train and test MSE as a function of the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from prml.preprocess import GaussianFeature, PolynomialFeature, SigmoidalFeature\n",
    "from prml.linear import (\n",
    "    BayesianRegression,\n",
    "    EmpiricalBayesRegression,\n",
    "    LinearRegression,\n",
    "    RidgeRegression\n",
    ")\n",
    "\n",
    "from sklearn.metrics import mean_squared_error \n",
    "np.random.seed(1234)\n",
    "def create_toy_data(func, sample_size, std, domain=[0, 1]):\n",
    "    x = np.linspace(domain[0], domain[1], sample_size)\n",
    "    np.random.shuffle(x)\n",
    "    y = func(x) + np.random.normal(scale=std, size=x.shape)\n",
    "    return x, y\n",
    "\n",
    "def sinusoidal(x):\n",
    "    return np.sin(2 * np.pi * x)\n",
    "\n",
    "x_train, y_train = create_toy_data(sinusoidal, 10, 0.25)\n",
    "x_test = np.linspace(0, 1, 100)\n",
    "y_test = sinusoidal(x_test)\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.scatter(x_train, y_train, facecolor=\"none\", edgecolor=\"b\", s=50, label=\"training data\")\n",
    "plt.plot(x_test, y_test, label=\"$\\sin(2\\pi x)$\")\n",
    "plt.plot(x_test, y_test, \"-g\", label=\"Target Function\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "x = np.linspace(-1, 1, 100)\n",
    "X_polynomial = PolynomialFeature(11).transform(x[:, None])\n",
    "X_gaussian = GaussianFeature(np.linspace(-1, 1, 11), 0.1).transform(x)\n",
    "X_sigmoidal = SigmoidalFeature(np.linspace(-1, 1, 11), 10).transform(x)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "for i, X in enumerate([X_polynomial, X_gaussian, X_sigmoidal]):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    for j in range(12):\n",
    "        plt.plot(x, X[:, j])\n",
    "txt=\"Polynomial, Gaussian and Sigmoidal basis functions\"\n",
    "plt.figtext(0.5, 0.01, txt, wrap=True, horizontalalignment='center', fontsize=12)\n",
    "y = np.dot(X, np.array([1, 2, 3, 4, 5]))\\\n",
    "    + np.random.randn(100) * 0.1\n",
    "mean_squared_error(y,x) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
